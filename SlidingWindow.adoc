# Sliding windows
:toc:
:sectnums:

Like the Two pointers approach, sliding windows xork the same with arrays and strings. The important thing is that they're with ordered elements.

## Introduction

Such as a Two pointer algorithm, this algorithm is another common approach to solving problems related to arrays (or any iterative type).

A sliding window is actually implemented using two pointers ! Before we start, we need to talk about the concept of subarray.

## Subarrays

Given an array, a *subarray* is a contiguous section of the array. All the elements must be adjacent to each other in the original array and in their original order. For example, with the following array: `[1, 2, 3, 4]`, the subarrays grouped by length are:

* Subarray of length 1: `[1]`, `[2]`, `[3]`, `[4]`
* Subarray of length 2: `[1, 2]`, `[2, 3]`, `[3, 4]`
* Subarray of length 3: `[1, 2, 3]`, `[2, 3, 4]`
* Subarray of length 4: `[1, 2, 3, 4]`

**A subarray can be defined by two indices, the start and end.** For example, with `[1, 2, 3, 4]`, the subarray `[3, 4]` has a starting index of _1_ and an ending index of _2_. Let's call the starting index the **left bound** and the ending index the **right bound**. Another name of subarray in this context is also named *window*

## Valid subarray

A common patern you'll see in array problems involves the idea of a _valid_ subarray. The problem description will either explicitly or implicitly define what makes a subarray _valid_. We can split it into 2 parts:

. A constraint metric. This is an attribute of a subarray. For example, the sum of the subarray, the number of unique elements in the subarray, the frequency of a specific element, etc...

. A numeric restriction on athe constraint metric.

For example, let's say a problem declares a subarray is valid if it has a sum less than or equal to ` <= 10`. A subarray is considered valid if its constraint metric conforms to the numeric restriction, i.e, the sum is less than or equal to `10`.

### The idea

Sliding window is used to analyze and find the valid subarrays of an array. The idea behind a sliding window is to maintain two variables, `left` and `right`. At any given time, `left` represents the left bound of our window, and `right` represents the right bound of our window. Remember that _window_ here is another word for subarray.

Initially we set `left = right = 0`, which means that the first window we consider is just the first element of the array on its own. We want to expand the size of our _window_, and we do that by incrementing `right`, when we increment `right`, this is like _adding_ a new element to the window.

But what if after adding a new element, the wubarray becomes invalid ? For example, let's say adding a new element on the right makes the sum of the subarray too large ? We need to _remove_ some elements from our window until it becomes valid again. To _remove_ elements, we can increment `left`, which will make the window shrink.

**Remember: `left` and `right` represent the bounds of our window at any given time, so incrementing `left` is equivalnet to removing the left-most element**

To explain why this algorithm works, let's look at a sspecific example. Let's say that we are given a positive integer array `nums` and an integer `k`. We need to find the length of the longest subarray that has a sum less than or equal to `k`. For this example, let `nums = [3, 2, 1, 3, 1, 1]` and `k = 5`.

Initially we have `left = right = 0`, so our window is only the first element: `[3]`. Now let's expand to the right until the constraint is broken. This will occur when `left = 0, right = 2` and our window is: `[3, 2, 1]`. The sub here is `6`, which is greater than `k`. We must now shrink the window from the left until the constraint is no longer broken. After removing one element, the window becomes valid again: `[2, 1]`.

Why is it correct to remove this `3` and forget about it for the rest of the algorithm ? Because the input only has positive integers, a longer subarray directly equals a larger sum. We know that `[3, 2, 1]` already results in a sum that is too large. There is no way for us to ever have a valid window again if we keep `3` because if we were to add any more elements from te right, the sum would only get larger, and it's not like we can include the `3` without also including the `2` or `1`, since that would violate the definition of a subarray. That's why we can forget about the `3` for the rest of the algorithm.

### Solving problems using the sliding window

Whenever you see a problem that not only describes subarray being *valid*, but also asks you to find these subarrays, you should immediately think about a sliding window algorithm.

Often, the problem will asks you to find the *best* valid subarray. The problem will define what makes one subarray *better* than another. For instance, a prblem might ask you to find the *longest* valid subarray.

Another common type of problem is one that asks you to find the number of valid subarrays. We'll take a deeper look at this type of problem later in the article.

Here is a preview of some of the example problems that we will look at in this article, to help you better understand what sliding window problem looks like:

* Find the longest subarray with a sum less than or equal to `k` (constraint metric = sum)
* Find the longest substring that has a most one `0` (constraint metric = number of zeros)
* Find the number of subarrays that have a product less than `k` (constraint metric = product)

### Implementation

Now that you have an idea of how sliding window works, let's talk about how to implement it. For this part, we will use the previous example (find the longest subarray with a sum less than or equal to `k`).

#### Constraint metric identifications

First, we need to identify the *constraint metric*. In our example, the constraint metric is the sum of the window. How do we keep track of the sum of the window as elements are added and removed ? One way that we could do it is by keeping the window in a separate array. When we add elements from the right, we add them to our array. When we remove elements from the left, we remove the corresponding elements from the array. This way, we can always find the sum of our current window just by summing the elements in the separate array.

This is very inefficient as removing elements and finding the sum of the window will be _O(n)_ operations. How can we do better than that ?

#### Constraint metrics improved

We don't actually need to store the window in a separate array. All we need is some variable, let's call it `curr`; that keeps track of the current sum. When we add a new element from the right, we just do `curr += nums[right]`. When we remove an element from the left, we just do `curr -= nums[left]`. This way, all operations are done in _O(1)_.

_Notice here that our window only exists as an idea. We are not literally maintaining it with an array. We only need `left` and `right` to remember its bound, and `curr` to track the constraint metric._

#### Moving pointers

Newt, how do we move the pointers `left` and `right` ? Remember, we want to keep expanding our window, and the window always slides to the right - it just might shrink a few times along the way. Because `right` is always moving forward, we can use a for loop to iterate `right` over the input. In each iteration of the for loop, we will be adding the element `nums[right]` to our window.

But what about `left`, we are shrinking our window. We only shrink our window when it becomes invalid. By maintaining `curr`, we can easily tell if the current window is valid simply by checking its value. If `curr > k`, the window gets invalid.

Let's say `nums = [1, 1, 1, 3]` and `k = 3`. When we arrive at the `3` and add it to thr window, the windoow becomes invalid, and `curr` will be equal to `6`. We need to remove elements from the left before the window becomes valid again.

This suggest that we should use a while loop to perform the removals. The condition ill be `while curr > k` (while the window is said _invalid_). To perform the removals, we do `curr -= nums[left]` and then increment `left` in each iteration of the while loop.

We now have a systematic way to slide our window across the input while maintaining its validity. How do we update the answer ? In each for loop iteration, after the while loop, we know the current window is valid. We can write code here to update thhe answer. The formula for the length of a window is `right - left + 1`.

##### Pseudo code

```
function fn(nums, k):
    left = 0
    curr = 0
    answer = 0
    for (int right = 0; right < nums.length; ++right) {
        curr += nums[right]
        while (curr > k) {
            curr -= nums[left]
            left++
        }
        answer = max(answer, right - left + 1)
    }
    return answer
```

##### Pseudo code template

```
function fn(nums, k):
    left = 0
    for (int right  = 0; right < nums.length; ++right):
        Do some logic to "add" element at nums[right] to window
        
        while WINDOW_IS_INVALID:
            Do some logic to "remove" element at nums[left] from our window
            left++
        
        Do some logic to update the answer.
```

##### Why is sliding window efficient ?

For any array, how many subarrays are there ? If the array has a length of `n`, there are `n` subarrays of length `1`. Then there are `n - 1` subarrays of length `2` (every index except the last one can be a starting index), `n - 2` subarrays of lengt `3` and so on until there is only `1` subarray of length `n`. This means there are `(n * (n + 1)) / 2` subarrays. (it's the partial sum)

In terms of time complexity, any alforithm that looks at every subarray will be at leans _O(n^2)_, which is usually too slow. A sliding window guarantees a maximum of _2n_ window iteration - the right pointer can move _n_ times and the left pointer can move _n_ time as well. This means if the logic done for each window is _O(1)_, sliding window algorithms run in _O(n)_, which is must faster !

_You may be thinking: there is a while loop inside of the for loop, isn't the time complexity O(n^2) ? The reason it is still O(n) is that the while loop can only iterate n times in total for the entire alforithm. (left starts at 0, only increases, and never exceeds n). If the while loop were to run n times on one iteration of the for loop, that would mean it wouldn't run at all for all the other iterations of the for loop. This is what we refer to as amortized analysis - even though the worst case for an iteration inside the for loop is O(n), it averages out to O(1) when you consider the entire runtime of the algorithm_

## Now let's look at some sliding window example.

### Example 1

Given an array of positive integers called `nums` and an integer `k`, find the length of the longest subarray whose sum is less than or equal to `k`.

###### Intuition

Let's use an integer named `curr` thats tracks the sum of the current window. Since the problem wants subarrays whose sum is less than or equal to `k`, we want to maintain `curr <= k`, let's look at an example where `nums = [3, 1, 2, 7, 4, 2, 1, 1, 5]` and `k = 8`.

The window starts empty by default, be we can grow it to `[3, 2, 1]` while maintaining the constraint. However, after adding the `7`, the window's sum becomes too large. We need to tighten the window until the sum is below `8` again, which doesn't happen until our window looks like `[7]`. When we try to add the next element, our window again becomes too large, and we need to remove the `[7]`. When we try to add the next element, our window again becomes too large, and we need to remove the `7` which means we have `[4]`. We can now grow the window until it looks like `[4, 2, 1, 1]`, but adding the next element makes the sum too large again. We remove elements from the left until it fits the constraint again, which happens at `[1, 1, 5]`. The longest subarray we found was `[4, 2, 1, 1]` which meanss the answer is `4`.

When we add an element to the window by moving the right bound, we just do `cur += value`. When we remove an element from the window by moving the left bound, we just do `curr -= value`. We should remove elements so long as `curr > k`.

###### Code solution

```java
public int findLength(int[] nums, int k) {
    int ans = 0;
    int left = 0;
    int curr = 0;
    
    for (int right= 0; right < nums.length; ++right) {
        curr += nums[right];
        while (curr > k) {
            curr -= nums[left];
            ++left;
        }
        ans = Math.max(ans, right - left + 1);
    }
    return ans;
}
```
Given a subarray starting at `left` and ending at `right` (pointer left and pointer right), the length is `right - left + 1`. As mentioned before, this algorithm has a time complexity of _O(n)_ since all work done inside the for loop is said *amortized* _O(1)_, where _n_ is the length of `nums`. The space complexity is constant because we are only using 3 integers variables.

### Example 2

We are given a binary string `s` (a string containing only `0` and `1`). You may choose up to one `0` and flit it to `1`. What is the length of the longest substring you can acheve that contains only `1` ? 

For exmaple, given `s = "1101100111"`, the answer is `5`, if you perform the flip at index `2`, the string becomes `1111100111`.

###### Intuition

Because the string can only contain `1` and `0`, another way to look at this problem is "what is the longest substring that contains *at most one* `0` ? This makes it easy for us to solve this sliding window where our condition is `window.cound("0") <= 1`. We can use an integer `curr` that keeps track of how many `0` we current have in our window.

###### Code solution

```java
public int findLength(String s) {
    int left = 0;
    int curr = 0;
    int ans = 0;
    
    for (int right = 0; right < s.length; ++right) {
        if (s.charAt(right) == '0') {
            curr++;
        }
        
        while (curr > 1) {
            if (s.charAt(left) == '0') {
                curr--;
            }
            
            left++;
        }
        ans = Math.max(ans, right - left + 1);
    }
    return ans;
}
```
Like in the previous example, this problem runs in _O(n)_ time, where _n_ is the length of `s`, as the work done in each loop iteration is *amortized* constant. Only a few integer variables are used as well which means this algorithm uses _O(1)_ space.

### Number of subarrays

If a problem asks for *the number of subarrays* that fit some constraints, we can still use sliding window, but we need to use a neat math trick to calculate the number of subarrays.

Let's say that we are using the sliding window algorithm, we have learned and currently have a window `(left, right)`. How many valid window *ends* at index `right` ?

There's the current window `(left, right)`, then `(left + 1, right)`, `(left + 2, right)`, and so on until `(right, right)` (only the element at `right`).

You can fix this right bound and then choose any value between `left` and `right` inclusive for the left boound. Therefore, the number of valid windows *ending* at index `right` is equal to the size of the window, which we know is `right - left + 1`.

#### Subarray product less than k

##### Example

Given an array of positive integers named `nums` and an integer `k`, return the number of subarrays where the product of all te elements in the subarray is strictly less than `k`.

For example, given the input `nums = [10, 5, 2, 6], k = 100`, the answer is `8`. The subarrays with products that are less than `k` are:

`[10], [5], [2], [6], [10, 5], [5, 2], [2, 6], [5, 2, 6]`

###### Intuition

To demonstrate the property we have just learned, let's look at the example in the description. When we reach index `2`. That means that there are `2` valid subarrays that end here (`[2]` and `[5, 2]`).

Recall that in the previous example, we updated the answer (longest length) after the while loop, when the window must be valid. Here, we can add the current size of the window to our answer instead. The constraint that determines if a window is valid is that the product is less than `k` value.

Additionnaly, note that if `k <= 1` we can never have any valid windows, so we can just return `0` immediately.

The constraint metric is: product of the window. The numeric restriction is `< k`. If we use an integer `curr` to represent the current product of the window, the condition that makes a window invalid is `curr >= k`.

Add element to the window through `curr *= nums[right]` and remove them through `curr /= nums[left]`. After the while loop, we know the window is valid. Add the window size `right - left + 1` to your answer.

###### Code

```java
public int numSubarrayProductLessThanK(int[] nums, int k) {
    if (k <= 1) {
        return 0;
    }

    int left = 0;
    int ans = 0;
    int curr = 1;
    
    for (int right = 0; right < nums.length; ++right) {
        curr *= nums[right];
        while (curr >= k) {
            curr /= nums[left];
            left++;
        }
        ans += right - left + 1;
    }
    return ans;
}
```
Again, the work is done in each loop iteration is amortized, so this algorithm has a runtime of _O(n)_ where _n_ is the length of `nums`, and _O(1)_ space.

#### Fixed window size

In the examples, we looked at above, our window size was dynamic. We tried to expand it to the right as much as we could, while keeping the window within some constraint and removed elements from the left when the wonstraint was violated. Sometimes, a problem will specify a *fixed* length `k`.

These problems are quite easy because the difference between any two adjacent windows is only two elements (we add one element on the right and remove onez element to maintain the length).

Start by building the first window (from index `0` to `k - 1`). Once we have a window of size `k`, if we add an element at index `i`, we need to remove the element at index `i - k`. For example, `k = 2` and you currently have elements at indices `[0, 1]`. Now we add `2` leading to `[0, 1, 2]`. To keep the window size at `k = 2`, we need to remove `2 - k = 0`: `[1, 2]`.

##### Pseudo code

```java
function fn(arr, k) {
    curr = some data to track the window
    
    // build of the first window
    for (int i = 0; i < k; ++i)
        Do something with curr or other variables to build first window
        
    ans = answer variable, probably equal to curr here depending on the problem
    for (int i = k, i < arr.length; i++)
        Add arr[i] to our window
        Remove arr[i - k] from the window
        Update ans
    
    return ans
}
```

##### Find sum of subarray with the largest sum whose length is k

Given an integer array `ǹums`, and an integer `k`, find the sum of the subarray with the largest sum whose length is `k`.

##### Intuition

As we mentioned above, we can build a window of length `k`, and then slide it along the array. Add and remove one element at a time to make sure the window stays size `k`. If we are adding the value at `i`, then we need to remove the value at `i - k`.

After we build the first window, we initialize our answer to `curr` to consider the first window's sum.

##### Code sample

```java
public int findBestSubarray(int[] nums, int k) {
    int curr = 0;
    for (int i = 0; i < nums.length; ++i) {
        curr += nums[i];
    }
    
    int ans = curr;
    for (int i = k; i < nums.length; ++i) {
        curr += nums[i] - nums[i - k];
        ans = Math.max(ans, curr);
    }
    return ans;
}
```
The total for loop iterations is equal to _n_ where _n_ is the length of `sum`, and the work done in each iteration is constant, giving this algorithm a time complexity of _O(n)_, using _O(1)_ space.

## Closing note

Sliding window is extremely common and versatile as a pattern. We only scratched the surface here because many sliding window problems will also need to use a hashmap.